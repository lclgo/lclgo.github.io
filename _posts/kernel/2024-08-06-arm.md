---
layout: post
title: "ARM架构"
category: kernel
date: 2024-08-06 21:00:00 +0800
---

## ARM cache和MMU

参考：<https://aijishu.com/a/1060000000456118>

在ARM架构中，L1 cache都是VIPT的，也就是当有一个虚拟地址送进来，MMU在开始进行地址翻译的时候，Virtual Index就可以去L1 cache中查询了，MMU查询和L1 cache的index查询是同时进行的。如果L1 Miss了，则再去查询L2，L2还找不到则再去查询L3。 注意在arm架构中，仅仅L1是VIPT，L2和L3都是PIPT。ARM的cache是弱一致性的，而x86的cache是强一致性的（强一致性：cache更新后，后续的读取为更新后的值；弱一致性：cache更新后，后续读取的值可能是更新前的值，也可能是更新后的值。）

<img src="https://github.com/Geass-LL/draw/raw/master/github-io/ARM-cache-MMU.png" style="zoom:50%" />

## cacheline

通过`cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size`获取CPU某一级cache的cacheline大小。一般是64。

cacheline更新时为整行更新，所以如果cacheline比较大可能导致cacheline伪共享，引起性能下降：

<https://www.cnblogs.com/diegodu/p/9340243.html>

* cache在不同的CPU之间有多个副本
* A CPU更新自己的cache，修改cacheline的位置A，更新后标记B CPU的cache Invalidate
* B CPU实际上只关注cacheline的位置B，但是因为检测到Invalidate后发生cachemiss

### Direct mapped cache

<https://blog.csdn.net/rong_toa/article/details/109274448>

在CPU需要访问内存时，根据内存地址首先计算cacheline的索引（取模），然后检查cacheline是否有效（Valid Bit）、是否为预期的内存（Tag）。如果是，根据CPU指定的offset获取对应的数据。

<img src="https://github.com/Geass-LL/draw/raw/master/github-io/direct-mapped-cache.png" style="zoom:50%" />
